{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Установка (при необходимости раскомментить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Uninstall previous version of WhiteBox\n",
    "# !pip3 uninstall --yes autowoe \n",
    "# # install requirements if Linux \n",
    "# # !pip3 install -r requirements.txt\n",
    "# # Install WhiteBox\n",
    "# !python3 setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from copy import deepcopy\n",
    "\n",
    "from autowoe import ReportDeco, AutoWoE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и подготовка обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./example_data/train_demo.csv\",\n",
    "                    low_memory=False,\n",
    "                    index_col=\"line_id\",\n",
    "                    parse_dates = [\"datetime_\" + str(i) for i in range(2)],)\n",
    "\n",
    "train = train.iloc[:, 50:100]\n",
    "\n",
    "num_col = list(filter(lambda x: \"numb\" in x, train.columns))\n",
    "num_feature_type = {x: \"real\" for x in num_col}\n",
    "\n",
    "date_col = filter(lambda x: \"datetime\" in x, train.columns)\n",
    "for col in date_col:\n",
    "    train[col + \"_year\"] = train[col].map(lambda x: x.year)\n",
    "    train[col + \"_weekday\"] = train[col].map(lambda x: x.weekday())\n",
    "    train[col + \"_month\"] = train[col].map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и подготовка тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./example_data/test_demo.csv\",\n",
    "                   index_col=\"line_id\", \n",
    "                   parse_dates = [\"datetime_\" + str(i) for i in range(2)])\n",
    "\n",
    "date_col = filter(lambda x: \"datetime\" in x, test.columns)\n",
    "for col in date_col:\n",
    "    test[col + \"_year\"] = test[col].map(lambda x: x.year)\n",
    "    test[col + \"_weekday\"] = test[col].map(lambda x: x.weekday())\n",
    "    test[col + \"_month\"] = test[col].map(lambda x: x.month)\n",
    "    \n",
    "test_target = pd.read_csv(\"./example_data/test-target_demo.csv\")[\"target\"]\n",
    "test[\"target\"] = test_target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели рекомендуется указать тип признаков для обучения.\n",
    "Поэтому создается словарь features_type с ключами: \n",
    "\n",
    "\n",
    "\"real\" -- вещественный признак,\n",
    "\n",
    "\"cat\" --  категориальный.\n",
    "\n",
    "Для признаков, которые не размечены, типы будут определены автоматом. Такой вариант будет работать, но качество порядочно просядет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = list(filter(lambda x: \"str\" in x, train.columns))\n",
    "cat_feature_type = {x: \"cat\" for x in cat_col}\n",
    "\n",
    "year_col = list(filter(lambda x: \"_year\" in x, train.columns))\n",
    "year_feature_type = {x: \"cat\" for x in year_col}\n",
    "\n",
    "weekday_col = list(filter(lambda x: \"_weekday\" in x, train.columns))\n",
    "weekday_feature_type = {x: \"cat\" for x in weekday_col}\n",
    "\n",
    "month_col = list(filter(lambda x: \"_month\" in x, train.columns))\n",
    "month_feature_type = {x: \"cat\" for x in month_col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cat_col + year_col + weekday_col + month_col + num_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature level constrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_type = dict(**num_feature_type,\n",
    "                     **cat_feature_type,\n",
    "                     **year_feature_type,\n",
    "                     **weekday_feature_type,\n",
    "                     **month_feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `features_monotone_constraints` - также можно указать зависимость целевой переменной от признака.Если заранее известно, что при возрастании признака feature_1, то эту информацию можно учесть в модели, добавив в словарь пару {feature_1: \"1\"}. Если же зависимость признака от целевой переменной обратная, то можно указать {feature_1: \"-1\"} Если про зависимость ничего неизвестно, но хочется, чтобы она была монотонная, можно указать 'auto'. Можно указать  {feature_1: \"0\"}, в случае, если установлено общее ограничение на монотонность, чтобы не распространять его на эту фичу. Если специальных условий нет, то можно не собирать этот дикт\n",
    "\n",
    "\n",
    "Рекомендуемое использование:\n",
    "\n",
    "1) В случае, если задано общее условие на монотонность, то можно собрать дикт {feature_1: \"0\", feature_2: \"0\"}, чтобы игнорировать это ограничение для признаков feature_1, feature_2\n",
    "\n",
    "2) В случае, если не задано общее условие на монотонность, то можно собрать дикт {feature_1: \"auto\", feature_2: \"auto\"}, чтобы установить это ограничение для признаков feature_1, feature_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_monotone_constraints = {'number_74': 'auto',  'number_83': 'auto'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `max_bin_count`  - через словарь max_bin_count можно задать число бинов для WoE кодирования, если для какого-то признака оно отлично от общего. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bin_count = {'number_47': 3, 'number_51': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Рекомендация\n",
    "В общем случае, в первый момент построения модели лучше не указывать специальных ограничений в features_monotone_constraints и max_bin_count. Если в результате анализа полученной модели разбиение оказалось неинтерпретируемым или нестабильным по отдельным признакам, но в целом по модели ок, то ограничить сложность разбиения отдельных призаков имеет смысл. Если разбивка большинства признаков в модели оказалась неудовлетворительная, то рекомендуется в первую очередь настраивать глобальные ограничения (см параметры модели max_bin_count, monotonic, min_bin_size и др ниже)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Общие параметры модели\n",
    "\n",
    "- `interpreted_model` - требуется ли интерпретируемость модели (условие на знак в коэффициентах логистической регрессии)\n",
    "\n",
    "- `monotonic` - Глобальное условие на монотонность. Если указано True, то для всех признаков по умолчанию будут строится только монотонные разбиения. Указать специальные условия для отдельных признаков можно используя features_monotone_constraints аргумент метода .fit\n",
    "\n",
    "- `max_bin_count` - Глобальное ограничение на число бинов. Указать специальные условия для отдельных признаков можно используя max_bin_count аргумент метода .fit\n",
    "\n",
    "- `select_type`  - способ ПРЕДВАРИТЕЛЬНОГО!!! (ЭТО ВАЖНО) отбора признаков. Если указать None, то будут отобраны признаки, у которых importance больше imp_th. Если указвать, например 50, то после предварительного отобра останется только 50 признаков самых важных признаков. Крайне не рекомендуется сильно ограничивать\n",
    "\n",
    "- `pearson_th` - пороговое значнеи для корреляции Пирсона. Используется на финальной стадии отбора признаков.\n",
    "Если корреляция вух признаков по модулю больше pearson_th, то будет выброшен тот, у которого \n",
    "информативность меньше\n",
    "\n",
    "- `auc_th` - пороговое значнеи для одномерной оценки качества признака\n",
    "\n",
    "- `vif_th` - пороговое значнеи для VIF признака\n",
    "\n",
    "- `imp_th` - порог по которому будет произведен отбор признаков, если указать select_type=None (см. ниже).\n",
    "\n",
    "- `th_const` порог по которому признак будет считаться константным. Все константные признаки в модели не учитываются. Если число валидных значений больше трешхолда, то колонка не константная (int). В случае указания float, трешхолд будет определяться как размер_выборки * th_const\n",
    "\n",
    "- `force_single_split` - иногда в силу ограничений на min_bin_size невозможно построить ниодной группировки на переменную. force_single_split=True заставит в этом случае построить единственно возмоджный сплит, в случае если при этом выделяется группа размера более чем th_const. False будет выкидывать этот признак\n",
    "\n",
    "\n",
    "- `th_nan` - порог по которому будет выделена отдельная категория для пропусков в данных.\n",
    "Если число пропусков меньше чем th_nan, то WoE значения для пропусков берется равным нулю.\n",
    "В противном случае пропущенные значения будут выделены в отдельную группу и для них отдельно\n",
    "будет рассчитано WoE значение.\n",
    "Так же влияет на редкие категории (менее th_cat). Если суммарно таких категорий будет менее th_nan, то обработка будет производиться по принципу отпределенному в `cat_merge_to`, иначе оценено по группе\n",
    "\n",
    "- `th_cat` - порог, по которой немногочисленные категории в категориальных признаках будут объединятся в отдельную группу\n",
    "\n",
    "\n",
    "- `woe_diff_th` - Возмодность смеджить наны и редкие категории с каким-то бином, если разница в вое менее woe_diff_th\n",
    "\n",
    "\n",
    "- `min_bin_size` - минимальный размер бина при группировке. Возможно int как число наблюдений и float как доля от выбрки\n",
    "\n",
    "- `min_bin_mults` - в ходе построения бинов будут протестированы возможные значения min_bin_size, \n",
    "min_bin_size * min_bin_mults[0], min_bin_size * min_bin_mults[1] ... . Ждем float > 1. Дефолт - (2, 4), в принципе можно не трогать\n",
    "\n",
    "- `min_gains_to_split` - возможные значения регуляризатора, которые будут протестированы в ходе построения биннинга\n",
    "\n",
    "\n",
    "- `auc_tol` - Чувствительность к AUC. Считаем, что можем пожертвовать auc_tol качества от максимального, чтобы сделать модель проще\n",
    "\n",
    "\n",
    "- `cat_alpha` - Регуляризатор для кодировщика категорий\n",
    "\n",
    "\n",
    "\n",
    "- `cat_merge_to` - группа для редких (менее th_cat) категорий либо новых на тесте\n",
    "         \"to_nan\" -- в группу nan, \n",
    "         \"to_woe_0\" -- отдельная группа с WoE = 0,\n",
    "         \"to_maxfreq\" - в самую большую группу,\n",
    "         \"to_maxp\" - в группу с наибольшей вероятностью события,\n",
    "         \"to_minp\" - в группу с наименьшей вероятностью события\n",
    "         \n",
    "- `nan_merge_to` - группа для НаНов\n",
    "         \"to_woe_0\" -- отдельная группа с WoE = 0,\n",
    "         \"to_maxfreq\" - в самую большую группу,\n",
    "         \"to_maxp\" - в группу с наибольшей вероятностью события,\n",
    "         \"to_minp\" - в группу с наименьшей вероятностью события  \n",
    "         \n",
    "         \n",
    "- `oof_woe` - если указать oof_woe=True, то WoE кодирование будет происходить по кросс-валидации. Если же False, то сразу на всей обучающей выборке.\n",
    "\n",
    "- `n_folds` - количество фолдов для внутренней кроссвалидации\n",
    "\n",
    "\n",
    "- `n_jobs` - число процессов, которое будет использовать модель \n",
    "\n",
    "- `l1_grid_size` - в данной модели на одном из шагов используется отбор признаков LASSO. l1_base_step -- размер сетки для перебора C\n",
    "\n",
    "- `l1_exp_scale` - шкала сетки для L1 отбора. 4 соответствует макс значению C порядка 3-4. Увеличивать, если необходимо сделать менее регуляризованную модель\n",
    "\n",
    "- `imp_type` - способ определения значимости признаков -- features importance (\"feature_imp\" - в общем случае более сложная модель) или permutation importance (\"perm_imp\" - в общем случае более простая модель)\n",
    "\n",
    "- `regularized_refit` - после отбора признаков полученная модель пересчитывается на всех данных. Стоит ли включать L1 при этом. Если нет, то в интерпретируемом режиме модель будет итеративно переобучаться, пока все веса не станут отрицательны. Если да - то аналогичное будет получаться закручиванием L1. Может быть полезно ставить False если нужна стат модель, те p-value на оценки\n",
    "\n",
    "- `p_val` - допустимый уровень p_value на оценки модели при условии обучении стат модели (regularized_refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_woe = AutoWoE(interpreted_model=True,\n",
    "                     monotonic=False,\n",
    "                     max_bin_count=5,\n",
    "                     select_type=None,\n",
    "                     pearson_th=0.9,\n",
    "                     auc_th=.505,\n",
    "                     vif_th=10.,\n",
    "                     imp_th=0,\n",
    "                     th_const=32,\n",
    "                     force_single_split=True,\n",
    "                     th_nan=0.01,\n",
    "                     th_cat=0.005,\n",
    "                     woe_diff_th=0.01,\n",
    "                     min_bin_size=0.01,\n",
    "                     min_bin_mults=(2, 4),\n",
    "                     min_gains_to_split=(0.0, 0.5, 1.0),\n",
    "                     auc_tol=1e-4,\n",
    "                     cat_alpha=100,\n",
    "                     cat_merge_to=\"to_woe_0\",\n",
    "                     nan_merge_to=\"to_woe_0\",\n",
    "                     oof_woe=True,\n",
    "                     n_folds=6,\n",
    "                     n_jobs=4,\n",
    "                     l1_grid_size=20,\n",
    "                     l1_exp_scale=6,\n",
    "                     imp_type=\"feature_imp\",\n",
    "                     regularized_refit=False,\n",
    "                     p_val=0.05,\n",
    "                     debug=False\n",
    "        )\n",
    "\n",
    "auto_woe = ReportDeco(auto_woe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train` обучающая выборка\n",
    "\n",
    "- `target_name` - название целевой переменной\n",
    "\n",
    "- `features_type` - см выше описание дикта features_type. Возможно указание None для автозаполнения, но не рекомендуется\n",
    "\n",
    "- `group_kf` -  название колонки-группы для GroupKFold https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html\n",
    "\n",
    "- `max_bin_count` - см выше описание дикта max_bin_count. Можно ничего не передавать, если специальных условий не предусмотрено. Общее для всех условние задано в __init__\n",
    "\n",
    "- `features_monotone_constraints` - см выше описание дикта features_monotone_constraints. Можно ничего не передавать, если специальных условий не предусмотрено. Общее для всех условние задано в __init__\n",
    "\n",
    "- `validation` - возможность использовать валидацию в построении/отборе признаков. Можно не передавать. На текущий момент используется для 1) отбора признаков по p-value при построении стат модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autowoe.lib.selectors.selector_first] [INFO]  features [] contain too many nans or identical values\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tval_set's auc: 0.669849\n",
      "[autowoe.lib.selectors.selector_first] [INFO]  features ['number_47', 'number_48', 'number_49', 'number_50', 'number_51', 'number_52', 'number_53', 'number_54', 'number_55', 'number_59', 'number_61', 'number_62', 'number_63', 'number_64', 'number_65', 'number_66', 'number_67', 'number_69', 'number_71', 'number_73', 'number_74', 'number_75', 'number_76', 'number_77', 'number_78', 'number_79', 'number_80', 'number_81', 'number_86', 'number_88', 'number_89', 'number_90', 'number_93'] have low importance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autowoe.lib.autowoe] [INFO] number_56 processing...[autowoe.lib.autowoe] [INFO] number_57 processing...[autowoe.lib.autowoe] [INFO] number_60 processing...[autowoe.lib.autowoe] [INFO] number_58 processing...\n",
      "\n",
      "\n",
      "\n",
      "[autowoe.lib.autowoe] [INFO] number_68 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_70 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_72 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_82 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_83 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_84 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_85 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_87 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_91 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_92 processing...\n",
      "[autowoe.lib.autowoe] [INFO] number_94 processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autowoe.lib.autowoe] [INFO] string_0 processing..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autowoe.lib.autowoe] [INFO] dict_keys(['number_56', 'number_57', 'number_58', 'number_60', 'number_68', 'number_70', 'number_72', 'number_82', 'number_83', 'number_84', 'number_85', 'number_87', 'number_91', 'number_92', 'number_94', 'string_0']) to selector !!!!!\n",
      "[autowoe.lib.autowoe] [INFO] Feature selection...\n",
      "[autowoe.lib.selectors.composed_selector] [INFO] Feature number_91 removed due to low AUC value 0.44338676293622137\n",
      "[autowoe.lib.selectors.composed_selector] [INFO] Feature number_92 removed due to low AUC value 0.47071865222623344\n",
      "[autowoe.lib.selectors.composed_selector] [INFO] Feature number_94 removed due to low AUC value 0.4703547533092659\n",
      "[autowoe.lib.selectors.composed_selector] [INFO] Feature number_84 removed due to high VIF value = 27.10840123283844\n",
      "[autowoe.lib.selectors.composed_selector] [INFO] Feature number_85 removed due to high VIF value = 13.684275512730796\n",
      "[autowoe.lib.selectors.composed_selector] [INFO] Feature number_82 removed due to high VIF value = 12.22270266492445\n",
      "[autowoe.lib.selectors.composed_selector] [INFO] Features ['number_70']: aucs = [0.5548726835138388] was removed due to corr = [0.9033611979376442] with feat number_68: auc = 0.5861583634175692\n",
      "[autowoe.lib.selectors.utils] [INFO] C parameter range in [0.00029197080291970805:291.97080291970804], 20 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autowoe.lib.selectors.utils] [INFO] Result(score=0.67383445995881, reg_alpha=0.4199853688431133, is_neg=True, min_weights=number_87   -0.797020\n",
      "number_83   -0.473107\n",
      "number_72   -0.637883\n",
      "number_68    0.000000\n",
      "number_57    0.000000\n",
      "number_60    0.000000\n",
      "number_58    0.000000\n",
      "number_56    0.000000\n",
      "string_0    -0.366332\n",
      "dtype: float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autowoe.lib.utilities.refit] [INFO] Iter 0 of final refit starts with 4 features\n",
      "[autowoe.lib.utilities.refit] [INFO] Iter 1 of final refit starts with 3 features\n",
      "[autowoe.lib.utilities.refit] [INFO] Iter 2 of final refit starts with 2 features\n",
      "[autowoe.lib.utilities.refit] [INFO] Validation data checks\n",
      "[autowoe.lib.utilities.refit] [INFO] Iter 3 of final refit starts with 1 features\n",
      "[autowoe.lib.utilities.refit] [INFO] Validation data checks\n",
      "[autowoe.lib.autowoe] [INFO] number_72   -0.946073\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "auto_woe.fit(train[features + ['target']], \n",
    "             target_name=\"target\",\n",
    "             features_type=features_type,\n",
    "             group_kf=None,\n",
    "             max_bin_count=max_bin_count,\n",
    "             features_monotone_constraints=features_monotone_constraints,\n",
    "             validation=test\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791178112786152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = auto_woe.predict_proba(test)\n",
    "roc_auc_score(test['target'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791178112786152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = auto_woe.predict_proba(test[['number_72']], report=False)\n",
    "roc_auc_score(test['target'], pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    1/(1+EXP(-(((number_72)*(-0.946073434369114))+(-4.517344816747468)))) AS result\n",
      "FROM (\n",
      "    SELECT\n",
      "        (CASE WHEN number_72 IS NULL THEN -0.973791 WHEN number_72 <= 0.0 THEN 0.296192 ELSE -1.960456 END) AS number_72\n",
      "    FROM (\n",
      "        SELECT\n",
      "            (CASE WHEN number_72 IS NULL OR number_72 = 'NaN' THEN NULL ELSE number_72 END) AS number_72\n",
      "        FROM table\n",
      "    )\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(auto_woe.get_sql_inference_query('table'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные методы модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `private_features_type` - типизация признаков\n",
    "- `get_woe` - рабиение на бины и WoE значения в них\n",
    "- `get_split` - границы разбиения. Особо полезен для категориальных признаков\n",
    "\n",
    "\n",
    "##### Замечание: \n",
    "ReportDeco - обертка для построения отчета. Она не обязательна для обучения и применения модели, но обязательна для построения отчета (см последнюю ячейку).\n",
    "Для доступа к атрибутам самой модели необходимо обратится к атрибуту auto_woe.model декоратора\n",
    "Все атрибуты объекта-модели так же доступны через объект-отчета.\n",
    "Однако в пикл отчета будет весить существенно больше, так что для сохранения модели на инференс стоит сохранять только auto_woe.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "/mnt/alex/Whitebox_git/autowoe/lib/report/utilities_images/utilities_images.py:186: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  grp = df.groupby(col)['pred', 'Target'].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autowoe.lib.report.report_generator] [INFO] Successfully wrote ./AUTOWOE_REPORT_1/autowoe_report.html.\n"
     ]
    }
   ],
   "source": [
    "report_params = {\"automl_date_column\": \"report_month\", # колонка с датой в формате params['datetimeFormat']\n",
    "                 \"output_path\": \"./AUTOWOE_REPORT_1\", # папка, куда сгенерится отчет и сложатся нужные файлы\n",
    "                 \"report_name\": \"___НАЗВАНИЕ ОТЧЕТА___\",\n",
    "                 \"report_version_id\": 1,\n",
    "                 \"city\": \"Воронеж\",\n",
    "                 \"model_aim\": \"___ЦЕЛЬ ПОСТРОЕНИЯ МОДЕЛИ___\",\n",
    "                 \"model_name\": \"___НАЗВАНИЕ МОДЕЛИ___\",\n",
    "                 \"zakazchik\": \"___ЗАКАЗЧИК___\",\n",
    "                 \"high_level_department\": \"___ПОДРАЗДЕЛЕНИЕ___\",\n",
    "                 \"ds_name\": \"___РАЗРАБОТЧИК МОДЕЛИ___\",\n",
    "                 \"target_descr\": \"___ОПИСАНИЕ ЦЕЛЕВОГО СОБЫТИЯ___\",\n",
    "                 \"non_target_descr\": \"___ОПИСАНИЕ НЕЦЕЛЕВОГО СОБЫТИЯ___\"}\n",
    "\n",
    "auto_woe.generate_report(report_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
